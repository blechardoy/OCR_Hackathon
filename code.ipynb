{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-20T17:28:53.953348Z",
     "iopub.status.busy": "2025-02-20T17:28:53.952876Z",
     "iopub.status.idle": "2025-02-20T17:28:54.685418Z",
     "shell.execute_reply": "2025-02-20T17:28:54.684173Z",
     "shell.execute_reply.started": "2025-02-20T17:28:53.953312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "\n",
    "def download_and_unzip_kaggle_dataset(competition_name, download_path=\"./data\"):\n",
    "    if os.path.exists(download_path):\n",
    "        return\n",
    "    if not os.path.exists(download_path):\n",
    "        os.makedirs(download_path)\n",
    "    \n",
    "    command = [\n",
    "        \"kaggle\",\n",
    "        \"competitions\",\n",
    "        \"download\",\n",
    "        \"-c\",\n",
    "        competition_name,\n",
    "        \"-p\",\n",
    "        download_path\n",
    "    ]\n",
    "    try:\n",
    "        print(\"Téléchargement du dataset en cours...\")\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Le dataset pour la compétition '{competition_name}' a été téléchargé dans le dossier '{download_path}'\")\n",
    "        \n",
    "        for file in os.listdir(download_path):\n",
    "            if file.endswith(\".zip\"):\n",
    "                file_path = os.path.join(download_path, file)\n",
    "                print(f\"Décompression du fichier : {file}\")\n",
    "                try:\n",
    "                    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                        zip_ref.extractall(download_path)\n",
    "                    print(f\"Décompression terminée : {file}\")\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"Fichier ZIP supprimé : {file}\")\n",
    "                except zipfile.BadZipFile:\n",
    "                    print(f\"Erreur : Le fichier {file} n'est pas un ZIP valide.\")\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Erreur lors du téléchargement du dataset :\", e)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Assurez-vous que Kaggle est installé et configuré correctement.\")\n",
    "\n",
    "competition_name = \"intelligent-text-extraction\"\n",
    "download_path = \"./data\"\n",
    "download_and_unzip_kaggle_dataset(competition_name, download_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T17:09:29.462265Z",
     "iopub.status.busy": "2025-02-21T17:09:29.461938Z",
     "iopub.status.idle": "2025-02-21T17:09:36.066701Z",
     "shell.execute_reply": "2025-02-21T17:09:36.065563Z",
     "shell.execute_reply.started": "2025-02-21T17:09:29.46224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import functools\n",
    "import operator\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from skimage.filters import threshold_local\n",
    "import torch\n",
    "import shutil\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération de tous les IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T17:09:36.068908Z",
     "iopub.status.busy": "2025-02-21T17:09:36.068262Z",
     "iopub.status.idle": "2025-02-21T17:09:37.2902Z",
     "shell.execute_reply": "2025-02-21T17:09:37.288375Z",
     "shell.execute_reply.started": "2025-02-21T17:09:36.068844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TEST = False\n",
    "\n",
    "def get_all_ids(dir):\n",
    "    ids = []\n",
    "    for filename in os.listdir(dir):\n",
    "        if filename.endswith(\".png\"):\n",
    "            file_id = os.path.splitext(filename)[0]\n",
    "            ids.append(file_id)\n",
    "    return ids\n",
    "\n",
    "if TEST:\n",
    "    dir = \"data/test/images\"\n",
    "else:\n",
    "    dir = \"data/train/images\"\n",
    "ids = get_all_ids(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédictions des bounding boxes (sans texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Détection des bboxes RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RF_bboxes(image_path, contrast_window_size=5, contrast_tresh_value=40, dbscan_eps=60, dbscan_min_samples=50):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Impossible de charger l'image: {image_path}\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # --- PARTIE 1: DÉTECTION DES ZONES ULTRA-CONTRASTÉES ---\n",
    "\n",
    "    local_thresh = threshold_local(gray, contrast_window_size, offset=0, method='gaussian')\n",
    "    contrast = np.abs(gray.astype(np.float32) - local_thresh)\n",
    "\n",
    "    # --- PARTIE 2: FILTRAGE DES ZONES À CONTRASTE ÉLEVÉ ---\n",
    "\n",
    "    contrast_thresh = np.zeros_like(contrast, dtype=np.uint8)\n",
    "    contrast_thresh[contrast > contrast_tresh_value] = 255\n",
    "\n",
    "    # --- PARTIE 3: EXTRACTION DES BOUNDING BOXES VIA CLUSTERING ---\n",
    "\n",
    "    points = np.column_stack(np.where(contrast_thresh > 0))\n",
    "    db = DBSCAN(eps=dbscan_eps, min_samples=dbscan_min_samples).fit(points)  #50,20\n",
    "    labels = db.labels_\n",
    "    unique_labels = set(labels)\n",
    "    unique_labels.discard(-1)\n",
    "\n",
    "    bboxes = []\n",
    "    for label in unique_labels:\n",
    "        cluster_points = points[labels == label]\n",
    "        x_min = np.min(cluster_points[:, 1])\n",
    "        y_min = np.min(cluster_points[:, 0])\n",
    "        x_max = np.max(cluster_points[:, 1])\n",
    "        y_max = np.max(cluster_points[:, 0])\n",
    "        bbox = [[x_min, y_min], [x_max, y_min], [x_max, y_max], [x_min, y_max]]\n",
    "        bboxes.append(bbox)\n",
    "\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion image -> texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(mat, angle_deg):\n",
    "        (h, w) = mat.shape[:2]\n",
    "        center = (w / 2, h / 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle_deg, 1.0)\n",
    "        cos = np.abs(M[0, 0])\n",
    "        sin = np.abs(M[0, 1])\n",
    "        nW = int((h * sin) + (w * cos))\n",
    "        nH = int((h * cos) + (w * sin))\n",
    "        M[0, 2] += (nW / 2) - center[0]\n",
    "        M[1, 2] += (nH / 2) - center[1]\n",
    "        rotated = cv2.warpAffine(mat, M, (nW, nH),\n",
    "                                flags=cv2.INTER_CUBIC,\n",
    "                                borderMode=cv2.BORDER_CONSTANT,\n",
    "                                borderValue=(255, 255, 255))\n",
    "        return rotated\n",
    "\n",
    "def deskew_minAreaRect(gray_img, angle_threshold=2):\n",
    "    _, bin_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    coords = np.column_stack(np.where(bin_img > 0))\n",
    "    if len(coords) == 0:\n",
    "        return gray_img, 0\n",
    "    rect = cv2.minAreaRect(coords)\n",
    "    (cx, cy), (w, h), angle = rect\n",
    "    if w < h:\n",
    "        angle += 90\n",
    "    if abs(angle) < angle_threshold:\n",
    "        angle = 0\n",
    "    angle -= 90\n",
    "    rotated = rotate_image(gray_img, -angle)\n",
    "    return rotated\n",
    "\n",
    "def get_texts(bboxes, image_path):\n",
    "    image = Image.open(image_path)\n",
    "    texts = []\n",
    "    for bbox in bboxes :\n",
    "        (x0, y0), (x1, y1) = bbox[0], bbox[2]\n",
    "        cropped_img = image.crop((x0-10, y0-10, x1+10, y1+10)) #Crops élargis\n",
    "\n",
    "        cv2_image = np.array(cropped_img)\n",
    "        if len(cv2_image.shape) == 3 and cv2_image.shape[2] == 4:\n",
    "            cv2_image = cv2_image[:, :, :3]\n",
    "        gray = cv2.cvtColor(cv2_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # --- Réduction du bruit ---\n",
    "        denoised = cv2.medianBlur(gray, 3)\n",
    "        kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n",
    "        denoised = cv2.morphologyEx(denoised, cv2.MORPH_OPEN, kernel_small, iterations=2)\n",
    "        oriented = deskew_minAreaRect(denoised)\n",
    "\n",
    "        #no_lines = remove_lines_by_contours(oriented)\n",
    "\n",
    "        # --- Reconnaissance de texte (OCR) avec Tesseract ---\n",
    "        config = (\n",
    "        \"--oem 1 \"  # utilise le moteur LSTM\n",
    "        \"--psm 10 \"  # traite l'image comme une seule ligne de texte\n",
    "        \"-c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "        )\n",
    "        recognized_text = pytesseract.image_to_string(oriented, config=config)\n",
    "        texts.append(recognized_text.strip())\n",
    "    return texts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse de l'image : OCR puis conversion image -> text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T17:09:39.631054Z",
     "iopub.status.busy": "2025-02-21T17:09:39.63071Z",
     "iopub.status.idle": "2025-02-21T17:09:39.636177Z",
     "shell.execute_reply": "2025-02-21T17:09:39.634817Z",
     "shell.execute_reply.started": "2025-02-21T17:09:39.631028Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def analyze_image(image_path:str, language:str='en') -> list:\n",
    "    \"\"\"\n",
    "    Analyze the image to detect text using EasyOCR.\n",
    "\n",
    "    Parameters:\n",
    "    image_path (str): The path to the image file.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of tuples containing the bounding box, detected text, and confidence score for each detected text region.\n",
    "    \"\"\"\n",
    "    bboxes = get_RF_bboxes(image_path)\n",
    "    texts = get_texts(bboxes, image_path) ######\n",
    "    \n",
    "    resultat = [(bbox, text, 0) for bbox, text in zip(bboxes, texts)]\n",
    "    return resultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation des résultats au format .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T17:09:40.0683Z",
     "iopub.status.busy": "2025-02-21T17:09:40.067974Z",
     "iopub.status.idle": "2025-02-21T17:09:40.075193Z",
     "shell.execute_reply": "2025-02-21T17:09:40.073811Z",
     "shell.execute_reply.started": "2025-02-21T17:09:40.068276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def transform_result(results: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    Transforms OCR results into Challenge's JSON format.\n",
    "\n",
    "    Args:\n",
    "        results (List[Dict[str, Any]]): A list of OCR results where each result is a dictionary containing:\n",
    "            - bbox (List[List[int]]): Bounding box coordinates.\n",
    "            - text (str): Detected text.\n",
    "            - prob (float): Confidence score.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string representing the transformed OCR results.\n",
    "    \"\"\"\n",
    "    form_data = []\n",
    "    for idx, (bbox, text, prob) in enumerate(results):\n",
    "        # Convert bounding box coordinates to integers\n",
    "        bbox = [[int(coord) for coord in point] for point in bbox]\n",
    "        box_extracted = [bbox[0], bbox[2]]\n",
    "        flat_box = [coord for sublist in box_extracted for coord in sublist]\n",
    "        \n",
    "        # Create the structure for each element\n",
    "        item = {\n",
    "            \"box\": flat_box,\n",
    "            \"text\": text,\n",
    "            \"label\": \"RF\", #get_label(flat_box, text),  #### WARNING : Customize this field as needed !\n",
    "            \"words\": [{\"box\": flat_box, \"text\": text}],  # Each word is encapsulated in a 'words' list\n",
    "            \"linking\": [],  # This part can be used to link words if necessary\n",
    "            \"id\": idx\n",
    "        }\n",
    "        form_data.append(item)\n",
    "\n",
    "    # Convert to JSON\n",
    "    json_data = {\n",
    "        \"form\": form_data\n",
    "    }\n",
    "    # Convert JSON data to a formatted string\n",
    "    #json_output = json.dumps(json_data, indent=4, ensure_ascii=False)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enregistrement des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T17:09:40.507726Z",
     "iopub.status.busy": "2025-02-21T17:09:40.507399Z",
     "iopub.status.idle": "2025-02-21T17:10:44.717787Z",
     "shell.execute_reply": "2025-02-21T17:10:44.716696Z",
     "shell.execute_reply.started": "2025-02-21T17:09:40.5077Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1/119\n",
      "Image 2/119\n",
      "Image 3/119\n",
      "Image 4/119\n",
      "Image 5/119\n",
      "Image 6/119\n",
      "Image 7/119\n",
      "Image 8/119\n",
      "Image 9/119\n",
      "Image 10/119\n",
      "Image 11/119\n",
      "Image 12/119\n",
      "Image 13/119\n",
      "Image 14/119\n",
      "Image 15/119\n",
      "Image 16/119\n",
      "Image 17/119\n",
      "Image 18/119\n",
      "Image 19/119\n",
      "Image 20/119\n",
      "Image 21/119\n",
      "Image 22/119\n",
      "Image 23/119\n",
      "Image 24/119\n",
      "Image 25/119\n",
      "Image 26/119\n",
      "Image 27/119\n",
      "Image 28/119\n",
      "Image 29/119\n",
      "Image 30/119\n",
      "Image 31/119\n",
      "Image 32/119\n",
      "Image 33/119\n",
      "Image 34/119\n",
      "Image 35/119\n",
      "Image 36/119\n",
      "Image 37/119\n",
      "Image 38/119\n",
      "Image 39/119\n",
      "Image 40/119\n",
      "Image 41/119\n",
      "Image 42/119\n",
      "Image 43/119\n",
      "Image 44/119\n",
      "Image 45/119\n",
      "Image 46/119\n",
      "Image 47/119\n",
      "Image 48/119\n",
      "Image 49/119\n",
      "Image 50/119\n",
      "Image 51/119\n",
      "Image 52/119\n",
      "Image 53/119\n",
      "Image 54/119\n",
      "Image 55/119\n",
      "Image 56/119\n",
      "Image 57/119\n",
      "Image 58/119\n",
      "Image 59/119\n",
      "Image 60/119\n",
      "Image 61/119\n",
      "Image 62/119\n",
      "Image 63/119\n",
      "Image 64/119\n",
      "Image 65/119\n",
      "Image 66/119\n",
      "Image 67/119\n",
      "Image 68/119\n",
      "Image 69/119\n",
      "Image 70/119\n",
      "Image 71/119\n",
      "Image 72/119\n",
      "Image 73/119\n",
      "Image 74/119\n",
      "Image 75/119\n",
      "Image 76/119\n",
      "Image 77/119\n",
      "Image 78/119\n",
      "Image 79/119\n",
      "Image 80/119\n",
      "Image 81/119\n",
      "Image 82/119\n",
      "Image 83/119\n",
      "Image 84/119\n",
      "Image 85/119\n",
      "Image 86/119\n",
      "Image 87/119\n",
      "Image 88/119\n",
      "Image 89/119\n",
      "Image 90/119\n",
      "Image 91/119\n",
      "Image 92/119\n",
      "Image 93/119\n",
      "Image 94/119\n",
      "Image 95/119\n",
      "Image 96/119\n",
      "Image 97/119\n",
      "Image 98/119\n",
      "Image 99/119\n",
      "Image 100/119\n",
      "Image 101/119\n",
      "Image 102/119\n",
      "Image 103/119\n",
      "Image 104/119\n",
      "Image 105/119\n",
      "Image 106/119\n",
      "Image 107/119\n",
      "Image 108/119\n",
      "Image 109/119\n",
      "Image 110/119\n",
      "Image 111/119\n",
      "Image 112/119\n",
      "Image 113/119\n",
      "Image 114/119\n",
      "Image 115/119\n",
      "Image 116/119\n",
      "Image 117/119\n",
      "Image 118/119\n",
      "Image 119/119\n"
     ]
    }
   ],
   "source": [
    "output_folder = 'output_classif'\n",
    "if os.path.exists(output_folder):\n",
    "    shutil.rmtree(output_folder)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "ground_truth_folder = 'ground_truth_annotations'\n",
    "if os.path.exists(ground_truth_folder):\n",
    "    shutil.rmtree(ground_truth_folder)\n",
    "os.makedirs(ground_truth_folder, exist_ok=True)\n",
    "\n",
    "for i, id in enumerate(ids) :\n",
    "    torch.cuda.empty_cache()\n",
    "    if TEST:\n",
    "        image_path = f'data/test/images/{id}.png'\n",
    "    else :\n",
    "        image_path = f'data/train/images/{id}.png'\n",
    "    results = transform_result(analyze_image(image_path))\n",
    "    json_output = json.dumps(results, indent=4, ensure_ascii=False)\n",
    "    with open(f'{output_folder}/{id}.json', 'w', encoding='utf-8') as f:\n",
    "        f.write(json_output)\n",
    "\n",
    "    if TEST:\n",
    "        input_path = f'data/test/annotations/{id}.json'\n",
    "    else :\n",
    "        input_path = f'data/train/annotations/{id}.json'\n",
    "        output_path = f'{ground_truth_folder}/{id}.json'\n",
    "\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        annotation = json.load(file)\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(annotation, f, ensure_ascii=False, indent=4)\n",
    "    print(f'Image {i+1}/{len(ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul du score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to put the true annotations in a folder and your predictions in another folder to compute results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T17:10:45.78364Z",
     "iopub.status.busy": "2025-02-21T17:10:45.783362Z",
     "iopub.status.idle": "2025-02-21T17:10:45.796738Z",
     "shell.execute_reply": "2025-02-21T17:10:45.79568Z",
     "shell.execute_reply.started": "2025-02-21T17:10:45.783606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Utils functions to compute result\n",
    "\n",
    "def clean_txt(s: str) -> str:\n",
    "    return re.sub(r'[^A-Z0-9]+', '', s.upper())\n",
    "\n",
    "\n",
    "get_rects = functools.partial(map, operator.itemgetter('box'))\n",
    "get_texts = functools.partial(map, operator.itemgetter('text'))\n",
    "\n",
    "\n",
    "def compute_overlap(gt: np.array, preds: np.array) -> np.array:\n",
    "    _gt = np.tile(np.expand_dims(gt, axis=1), (1, preds.shape[0], 1))\n",
    "    _p = np.tile(np.expand_dims(preds, axis=0), (gt.shape[0], 1, 1))\n",
    "\n",
    "    dx = np.minimum(_gt[:, :, 2], _p[:, :, 2]) - np.maximum(_gt[:, :, 0], _p[:, :, 0])\n",
    "    dy = np.minimum(_gt[:, :, 3], _p[:, :, 3]) - np.maximum(_gt[:, :, 1], _p[:, :, 1])\n",
    "\n",
    "    area = dx * dy\n",
    "    # valid area if dx > 0 and dy > 0\n",
    "    overlap = np.where(np.logical_and(dx > 0, dy > 0), area, 0)\n",
    "\n",
    "    return overlap\n",
    "\n",
    "\n",
    "def compute_area(rects: np.array) -> np.array:\n",
    "    return (rects[:, 2] - rects[:, 0]) * (rects[:, 3] - rects[:, 1])\n",
    "\n",
    "\n",
    "def compute_iou(gt: np.array, preds: np.array) -> np.array:\n",
    "    gt_area = compute_area(gt)\n",
    "    p_area = compute_area(preds)\n",
    "\n",
    "    _gt_area = np.tile(gt_area[:, np.newaxis], (1, preds.shape[0]))\n",
    "    _p_area = np.tile(p_area[np.newaxis, ], (gt.shape[0], 1))\n",
    "\n",
    "    overlap = compute_overlap(gt, preds)\n",
    "\n",
    "    _iou = overlap / (_gt_area + _p_area - overlap)\n",
    "\n",
    "    return np.amax(_iou, axis=1), np.argmax(_iou, axis=1)\n",
    "\n",
    "\n",
    "def compute_correct_rf(gt_texts: list, preds_texts: list, iou_results, iou_threshold=0.25) -> int:\n",
    "    iou, best_iou_id = iou_results\n",
    "    n_corrects = 0\n",
    "    for i_txt, text in enumerate(gt_texts):\n",
    "        if clean_txt(text) in clean_txt(preds_texts[best_iou_id[i_txt]]) and iou[i_txt] > iou_threshold:\n",
    "            n_corrects += 1\n",
    "\n",
    "    return n_corrects\n",
    "\n",
    "\n",
    "def compute_results(gt: list, preds: list):\n",
    "    gt = list(filter(lambda x: x['label'] == 'RF', gt))\n",
    "    gt_rects = np.array(list(get_rects(gt)))\n",
    "    gt_texts = list(get_texts(gt))\n",
    "\n",
    "    p_rects = np.array(list(get_rects(preds)))\n",
    "    p_texts = list(get_texts(preds))\n",
    "\n",
    "    n_gt_rects = len(gt_rects)\n",
    "\n",
    "    if n_gt_rects == 0:\n",
    "        return 1.0, 1.0\n",
    "\n",
    "    iou, best_iou_id = compute_iou(gt_rects, p_rects)\n",
    "    # print(\"IOU: \", iou)\n",
    "    # print(\"Best IOU ID: \", best_iou_id)\n",
    "    n_corrects = compute_correct_rf(gt_texts, p_texts, (iou, best_iou_id))\n",
    "\n",
    "    return np.sum(iou)/n_gt_rects, n_corrects/n_gt_rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T17:10:45.798114Z",
     "iopub.status.busy": "2025-02-21T17:10:45.797775Z",
     "iopub.status.idle": "2025-02-21T17:10:45.8148Z",
     "shell.execute_reply": "2025-02-21T17:10:45.813671Z",
     "shell.execute_reply.started": "2025-02-21T17:10:45.798077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_result(ground_truth, predictions):\n",
    "    means_ious = []\n",
    "    means_rf = []\n",
    "\n",
    "    for file in os.listdir(ground_truth):\n",
    "        with open(os.path.join(ground_truth, file), 'rb') as f:\n",
    "            gt_json = json.load(f)\n",
    "\n",
    "        pred_file = os.path.join(predictions, file)\n",
    "        if os.path.isfile(pred_file):\n",
    "            with open(pred_file, 'rb') as f:\n",
    "                preds_json = json.load(f)\n",
    "\n",
    "        else:\n",
    "            means_ious.append(0)\n",
    "            means_rf.append(0)\n",
    "            continue\n",
    "\n",
    "        file_iou, file_rf = compute_results(\n",
    "            gt_json['form'],\n",
    "            preds_json['form']\n",
    "        )\n",
    "        means_ious.append(file_iou)\n",
    "        means_rf.append(file_rf)\n",
    "    print(f\"IOU: {np.mean(means_ious) * 100:.2f}\")\n",
    "    print(f\"RF Correct: {np.mean(means_rf) * 100:.2f}\")\n",
    "    return means_ious, means_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T17:10:45.817698Z",
     "iopub.status.busy": "2025-02-21T17:10:45.817341Z",
     "iopub.status.idle": "2025-02-21T17:10:45.832492Z",
     "shell.execute_reply": "2025-02-21T17:10:45.83137Z",
     "shell.execute_reply.started": "2025-02-21T17:10:45.817668Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 89.97\n",
      "RF Correct: 30.10\n"
     ]
    }
   ],
   "source": [
    "gt_folder = os.path.join(os.getcwd(), ground_truth_folder)\n",
    "pred_folder = os.path.join(os.getcwd(), output_folder)\n",
    "\n",
    "iou, rf = compute_result(gt_folder, pred_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. From json to csv format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to create csv and make sure commas are replaced by semi-commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T17:16:57.855344Z",
     "iopub.status.busy": "2025-02-21T17:16:57.855017Z",
     "iopub.status.idle": "2025-02-21T17:16:57.868544Z",
     "shell.execute_reply": "2025-02-21T17:16:57.867616Z",
     "shell.execute_reply.started": "2025-02-21T17:16:57.85532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import pandas as pd\n",
    "\n",
    "# # Initialize an empty list to store the form data\n",
    "# form_data_list = []\n",
    "# ids = []\n",
    "# # Iterate through each file in the directory\n",
    "# for filename in os.listdir(output_folder):\n",
    "#     if filename.endswith('.json'):\n",
    "#         file_path = os.path.join(output_folder, filename)\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             data = json.load(file)\n",
    "#             form_data_list.append(data['form'])\n",
    "#             ids.append(filename.split('.')[0])\n",
    "# # Create a DataFrame from the form data list\n",
    "# target_form = pd.DataFrame()\n",
    "# target_form['id'] = ids\n",
    "# target_form['target'] = form_data_list\n",
    "# target_form['target'] = target_form['target'].astype(str)\n",
    "# target_form = target_form.replace(',', ';', regex=True)  # Here we replace , by ;\n",
    "# target_form['Usage'] = 'Public'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T17:17:05.133449Z",
     "iopub.status.busy": "2025-02-21T17:17:05.133027Z",
     "iopub.status.idle": "2025-02-21T17:17:05.146969Z",
     "shell.execute_reply": "2025-02-21T17:17:05.145739Z",
     "shell.execute_reply.started": "2025-02-21T17:17:05.133416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#target_form.to_csv('sample_submission.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Example of a Random Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def submit():\n",
    "#     start_path = \"/kaggle/input/intelligent-text-extraction/test/images\"\n",
    "    \n",
    "#     dataframe_liste = []\n",
    "#     for root, dirs, files in os.walk(start_path):\n",
    "#         for file in files:\n",
    "#             image_path = os.path.join(root, file)\n",
    "#             image_id = os.path.basename(image_path).split(\".\")[0]\n",
    "#             image = Image.open(image_path)\n",
    "    \n",
    "#             ### change code here to incorporate your predictions\n",
    "#             box = list(np.random.randint(0, 4000, 4))\n",
    "#             text = \"ETY017359D3\"\n",
    "#             ###\n",
    "            \n",
    "#             target = [{'box': box, 'text': text}]\n",
    "#             target_tocsv = str(target).replace(',', ';')\n",
    "#             line = {\"id\": image_id, \"target\": target_tocsv, \"Usage\": \"Public\"}\n",
    "#             dataframe_liste.append(line)\n",
    "    \n",
    "#     df = pd.DataFrame(dataframe_liste)\n",
    "#     df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "# submit()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11063785,
     "sourceId": 91851,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
